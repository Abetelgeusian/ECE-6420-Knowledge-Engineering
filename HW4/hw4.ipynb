{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ccd8d495",
   "metadata": {},
   "source": [
    "# Homework 4: Preprocessing \n",
    "\n",
    "## Introduction\n",
    "\n",
    "A crucial step when using machine learning algorithms on real-world datasets is preprocessing. This homework will give you some practice of data preprocessing and building a supervised machine learning pipeline on a real-world dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87b92ef4",
   "metadata": {},
   "source": [
    "## Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c65a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.compose import ColumnTransformer, make_column_transformer\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import cross_val_score, cross_validate, train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, OrdinalEncoder\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d59f3f28",
   "metadata": {},
   "source": [
    "## Exercise A: Introducing the dataset\n",
    "<hr>\n",
    "\n",
    "In this lab, you will be working on [the adult census dataset](https://www.kaggle.com/uciml/adult-census-income#). \n",
    "Download the CSV and save it as `adult.csv` under this homework folder. \n",
    "\n",
    "This is a classification dataset and the classification task is to predict whether income exceeds 50K per year or not based on the census data. You can find more information on the dataset and features [here](http://archive.ics.uci.edu/ml/datasets/Adult).\n",
    "\n",
    "The starter code below loads the data CSV (assuming that it is saved as `adult.csv` in this folder). \n",
    "\n",
    "_Note that many popular datasets have sex as a feature where the possible values are male and female. This representation reflects how the data were collected and is not meant to imply that, for example, gender is binary._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de5304c6",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "census_df = pd.read_csv(\"adult.csv\")\n",
    "census_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d3f5551",
   "metadata": {},
   "source": [
    "### Data splitting \n",
    "rubric={points:5}\n",
    "\n",
    "In order to avoid violation of the golden rule, the first step before we do anything is splitting the data. \n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Split the data into `train_df` (80%) and `test_df` (20%) with `random_state = 24`. Keep the target column (`income`) in the splits so that we can use it in the exploratory data analysis.  \n",
    "\n",
    "_Usually having more data for training is a good idea. But here I'm using 80%/20% split because this is kind of a big dataset for a modest laptop. A smaller training data means it won't take too long to train the model on your laptop. A side advantage of this would be that with a bigger test split, we'll have a more reliable estimate of the deployment performance!_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a3f190",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "664609bb3239b1f2db201db3a084249e",
     "grade": true,
     "grade_id": "cell-ede84e17a177c40c",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "train_df = None\n",
    "test_df = None\n",
    "\n",
    "# BEGIN YOUR CODE HERE\n",
    "\n",
    "\n",
    "# END YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc86ac4c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Exercise B: Exploratory data analysis (EDA)\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94e1c10e",
   "metadata": {},
   "source": [
    "Let's examine our `train_df`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a57216d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2159937",
   "metadata": {},
   "source": [
    "We see some missing values represented with a \"?\". Probably these were the questions not answered by some people during the census.  Usually `.describe()` or `.info()` methods would give you information on missing values. But here, they won't pick \"?\" as missing values as they are encoded as strings instead of an actual NaN in Python. So let's replace them with `np.nan` before we carry out EDA. If you do not do it, you'll encounter an error later on when you try to pass this data to a classifier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75700fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_nan = train_df.replace(\"?\", np.nan)\n",
    "test_df_nan = test_df.replace(\"?\", np.nan)\n",
    "train_df_nan.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a68eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_nan.sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc3b45e",
   "metadata": {},
   "source": [
    "The \"?\" symbols are now replaced with `NaN` values. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9712a0f7",
   "metadata": {},
   "source": [
    "### Visualizing features\n",
    "rubric={points:10}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "475622ec",
   "metadata": {},
   "source": [
    "#### Task B1\n",
    "rubric={points:4}\n",
    "\n",
    "`display` the information given by `train_df_nan.info()` and `train_df_nan.describe()` methods. \n",
    "In the case of `.describe()`, you can **optimally** use the `include=\"all\"` argument to show summary statistics of all  features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b3f98f",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b2743989e79d79206999089ddfe69e55",
     "grade": true,
     "grade_id": "cell-30f3e2214cfdbf33",
     "locked": false,
     "points": 4,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# BEGIN YOUR CODE HERE\n",
    "\n",
    "\n",
    "# END YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78ba9deb",
   "metadata": {},
   "source": [
    "#### Task B2 \n",
    "rubric={points:6}\n",
    "\n",
    "Visualize the histograms of numeric features \n",
    "\n",
    "Hint: use `dataframe.hist` to show the distribution of six numeric features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac56154a",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e26c83a5f396d331afce9aa64682664b",
     "grade": true,
     "grade_id": "cell-440f98becf9bfe9a",
     "locked": false,
     "points": 6,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# BEGIN YOUR CODE HERE\n",
    "\n",
    "\n",
    "# END YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a3df71",
   "metadata": {},
   "source": [
    "#### Task B3\n",
    "rubric={points:4}\n",
    "\n",
    "From the visualizations, which features seem relevant for the given prediction task?(You can pick multi-features)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "845365d6",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e7b871c4fc21893b77345f6b8679f02a",
     "grade": true,
     "grade_id": "cell-42db519234eb9146",
     "locked": false,
     "points": 4,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "<font color='red'>YOUR ANSWER HERE</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e1bc2bb",
   "metadata": {},
   "source": [
    "### Identify transformations to apply\n",
    "\n",
    "rubric={points:20}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e09c78d4",
   "metadata": {},
   "source": [
    "#### Task B4\n",
    "rubric={points:13}\n",
    "\n",
    "Identify what kind of feature transformations (`scaling`, `imputation`, `one hot encoding`) you would apply on each column in the dataset and fill in the table below accordingly. You may decide to apply any transformations on a certain column or entirely drop a column from your model. That's totally fine. \n",
    "\n",
    "As an example, we use imputation and One-Hot encoding for feature `occupation` here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c89e7e40",
   "metadata": {},
   "source": [
    "| Feature | Transformation |\n",
    "| --- | ----------- |\n",
    "| occupation | imputation, One-Hot Encoding |\n",
    "| age | |\n",
    "| workclass |  |\n",
    "| fnlwgt | |\n",
    "| education ||\n",
    "| education.num |  |\n",
    "| marital.status |  |\n",
    "| relationship |  |\n",
    "| race | |\n",
    "| sex |  |\n",
    "| capital.gain | |\n",
    "| capital.loss |  |\n",
    "| hours.per.week |  |\n",
    "| native.country |  |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6cd8f6f",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "fa24c28a3231c94c5f922ea4fc699f28",
     "grade": false,
     "grade_id": "cell-67ab20d3c82fa326",
     "locked": true,
     "points": 13,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "| Feature | Transformation |\n",
    "| --- | ----------- |\n",
    "| occupation | imputation, One-Hot Encoding |\n",
    "| age | scaling|\n",
    "| workclass | imputation, One-Hot Encoding |\n",
    "| fnlwgt | scaling |\n",
    "| education |One-Hot Encoding|\n",
    "| education.num | Scaling |\n",
    "| marital.status | One-Hot Encoding |\n",
    "| relationship | One-Hot Encoding |\n",
    "| race | Drop|\n",
    "| sex | One-Hot Encoding |\n",
    "| capital.gain | scaling |\n",
    "| capital.loss | scaling |\n",
    "| hours.per.week | scaling |\n",
    "| native.country | imputation, One-Hot Encoding |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "362d3515",
   "metadata": {},
   "source": [
    "#### Task B5\n",
    "rubric={points:5}\n",
    "\n",
    "Identify different feature types for applying different transformations. \n",
    "In particular, fill in the lists below.\n",
    "\n",
    "Hint:\n",
    "1. This dataset is very special - the features with missing values are categorical. So we don't create a list for `imputation_features`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e75724",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f7110445da3c456374c9de11648e68de",
     "grade": true,
     "grade_id": "cell-a19ac474c1373859",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# It's OK to keep some of the lists empty or add new lists.\n",
    "numeric_features = [] \n",
    "categorical_features = [] \n",
    "ordinal_features = [] \n",
    "binary_features = [] \n",
    "drop_features = []  # do not include these features in modeling\n",
    "passthrough_features = [] # do not apply any transformation\n",
    "\n",
    "# Example: numeric_features = [\"age\"] \n",
    "# BEGIN YOUR CODE HERE\n",
    "\n",
    "\n",
    "# END YOUR CODE HERE\n",
    "\n",
    "target = \"income\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5388a904",
   "metadata": {},
   "source": [
    "#### Task B6\n",
    "rubric={points:2}\n",
    "\n",
    "Is including the `race` feature for predicting income ethically a good idea? Briefly discuss.\n",
    "\n",
    "Hint:\n",
    "1. This question is a bit open-ended and there is no single correct solution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58378ce7",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "56c5838ee59fb77a273b721c8d1a0eaf",
     "grade": true,
     "grade_id": "cell-e1334ca6da3801d2",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "<font color='red'>YOUR ANSWER HERE</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25dc6367",
   "metadata": {},
   "source": [
    "### Separating feature vectors and targets  \n",
    "rubric={points:6}\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5938fcac",
   "metadata": {},
   "source": [
    "#### Task B7\n",
    "rubric={points:4}\n",
    "\n",
    "Create `X_train`, `y_train`, `X_test`, `y_test` from `train_df_nan` and `test_df_nan`.\n",
    "\n",
    "Hint:\n",
    "1. `income` is the target.\n",
    "2. The rest are considered as features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7159c656",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3ed9e4e497355b656151201c061c9f7c",
     "grade": true,
     "grade_id": "cell-e0948492f2ad7018",
     "locked": false,
     "points": 4,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Split the dataset, feature/target:\n",
    "# BEGIN YOUR CODE HERE\n",
    "\n",
    "\n",
    "# END YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cd8f680",
   "metadata": {},
   "source": [
    "#### Task B8\n",
    "rubric={points:2}\n",
    "\n",
    "At this point, if you train kNN model on `X_train` and `y_train`, would it work? Why or why not?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9ee22a7",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "bd6387ed6f904f23e5c9337bd26f2f49",
     "grade": true,
     "grade_id": "cell-f0a5e4962c33bbdf",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "<font color='red'>YOUR ANSWER HERE</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc0226a7",
   "metadata": {},
   "source": [
    "## Exercise C: Preprocessing\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c637a02",
   "metadata": {},
   "source": [
    "### Preprocessing using `sklearn`'s `ColumnTransformer` and `Pipeline`\n",
    "rubric={points:18}\n",
    "\n",
    "Let's carry out preprocessing using `sklearn`'s `ColumnTransformer` and `Pipeline`. Note that you can define pipelines in two ways: \n",
    "- by using [`Pipeline`](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html) and explicitly providing named steps\n",
    "- by using [`make_pipeline`](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.make_pipeline.html#sklearn.pipeline.make_pipeline), which automatically names the steps in the pipeline with their class names. \n",
    "\n",
    "Similarly you can create a column transformer in two ways:\n",
    "- by using [`ColumnTransformer`](https://scikit-learn.org/stable/modules/generated/sklearn.compose.ColumnTransformer.html)\n",
    "- by using [`make_column_transformer`](https://scikit-learn.org/stable/modules/generated/sklearn.compose.make_column_transformer.html) \n",
    "\n",
    "You may use the method of your choice but `make_pipeline` and `make_column_transformer` are highly recommended.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e96ce2",
   "metadata": {},
   "source": [
    "#### Task C1 \n",
    "rubric={points:10}\n",
    "\n",
    "Create a column transformer `preprocessor` based on transformations you want to apply on the data from [Task B5](#Task-B5).\n",
    "\n",
    "Hint\n",
    "1. There are several features with missing values. Fortunately, they are categorical features.\n",
    "2. Don't forget add `SimpleImputer(strategy='most_frequent')` and `OneHotEncoder` for your `categorical_features`.\n",
    "3. You can use `make_pipeline` to combine `SimpleImputer` and `OneHotEncoder`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ecf1142",
   "metadata": {
    "deletable": false,
    "lines_to_next_cell": 0,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "aa3ab60f86fd234e74babf884e24175d",
     "grade": true,
     "grade_id": "cell-d8d20476ac487747",
     "locked": false,
     "points": 10,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "preprocessor = None\n",
    "# BEGIN YOUR CODE HERE\n",
    "\n",
    "\n",
    "# END YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc51d7fd",
   "metadata": {},
   "source": [
    "#### Task C2 \n",
    "rubric={points:4}\n",
    "\n",
    "Transform the data by calling `fit_transform` on the training set. \n",
    "Then **print** or **display** the shape of the transformed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aaca43a",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8105aa5c74d1b3a047ff050b306ff2f4",
     "grade": true,
     "grade_id": "cell-3ef662c3ea19f095",
     "locked": false,
     "points": 4,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# BEGIN YOUR CODE HERE\n",
    "\n",
    "\n",
    "# END YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07f87b55",
   "metadata": {},
   "source": [
    "#### Task C3\n",
    "rubric={points:4}\n",
    "\n",
    "\n",
    "Why do we need to use a column transformer in this case? Briefly explain."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "713fcc2c",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "858862684b37ecfad39c4e5de30f1e18",
     "grade": true,
     "grade_id": "cell-7309c309f7fa5f78",
     "locked": false,
     "points": 4,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "<font color='red'>YOUR ANSWER HERE</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7738b69b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Exercise D: Building models\n",
    "<hr>\n",
    "\n",
    "Now that we have preprocessed features, we are ready to build models. Below, I'm providing the function we used in class which returns mean cross-validation score along with standard deviation for a given model. Feel free to use it to keep track of your results if you like. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47bbfc68",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "results_dict = {} # dictionary to store all the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15821aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def mean_std_cross_val_scores(model, X_train, y_train, **kwargs):\n",
    "    \"\"\"\n",
    "    Returns mean and std of cross validation\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model :\n",
    "        scikit-learn model\n",
    "    X_train : numpy array or pandas DataFrame\n",
    "        X in the training data\n",
    "    y_train :\n",
    "        y in the training data\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "        pandas Series with mean scores from cross_validation\n",
    "    \"\"\"\n",
    "\n",
    "    scores = cross_validate(model, X_train, y_train, **kwargs)\n",
    "\n",
    "    mean_scores = pd.DataFrame(scores).mean()\n",
    "    std_scores = pd.DataFrame(scores).std()\n",
    "    out_col = []\n",
    "\n",
    "    for i in range(len(mean_scores)):\n",
    "        out_col.append((f\"%0.3f (+/- %0.3f)\" % (mean_scores[i], std_scores[i])))\n",
    "\n",
    "    return pd.Series(data=out_col, index=mean_scores.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a47a1c5b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Baseline model \n",
    "rubric={points:6}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3982dad7",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Task D1\n",
    "rubric={points:3}\n",
    "\n",
    "Define a **pipeline** with two steps: `preprocessor` from [Task C2](Task-C2) and `scikit-learn`'s `DummyClassifier` with `strategy=\"prior\"` as your classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0970389f",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7f17a77b2ed561e4c651d47ebe5da2bd",
     "grade": true,
     "grade_id": "cell-f21d59b77ebc9be9",
     "locked": false,
     "points": 3,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# BEGIN YOUR CODE HERE\n",
    "\n",
    "\n",
    "# END YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c54c7810",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Task D2\n",
    "rubric={points:3}\n",
    "\n",
    "Carry out 5-fold cross-validation with the pipeline. Store the results in `results_dict['dummy]` above. \n",
    "\n",
    "> You may use the function `mean_std_cross_val_scores` above to carry out cross-validation and storing results. Refer to the class notes if you are unsure about how to use it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b92b081",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fa2bef41178a4d2b1e8c59652e845a3b",
     "grade": true,
     "grade_id": "cell-00cee76d80b6e733",
     "locked": false,
     "points": 3,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "results_dict[\"dummy\"] = None\n",
    "# BEGIN YOUR CODE HERE\n",
    "\n",
    "\n",
    "# END YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdbcb74b",
   "metadata": {},
   "source": [
    "Now let us show the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2964c90f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(results_dict).T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c2d09d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Trying different classifiers\n",
    "rubric={points:12}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "036dea0f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Task D3\n",
    "rubric={points:5}\n",
    "\n",
    "For each of the models (`DecisionTreeClassifier` and `KNeighborsClassifier`) in the starter code below:\n",
    "\n",
    "- Define a pipeline with two steps: `preprocessor` from [Task C2](#Task-C2) and the model as your classifier. \n",
    "- Carry out 5-fold cross-validation with the pipeline.  \n",
    "- Store the results in `results_dict`. \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af8dff4",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"decision tree\": DecisionTreeClassifier(),\n",
    "    \"kNN\": KNeighborsClassifier(),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e3790f",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6dc70200605d7cba32ceb40ca3f964b6",
     "grade": true,
     "grade_id": "cell-4a60eadeeea02f19",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(12345)\n",
    "# BEGIN YOUR CODE HERE\n",
    "\n",
    "\n",
    "# END YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "090ebc2d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Task D4\n",
    "rubric={points:2}\n",
    "\n",
    "Display all the results so far as a pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4149d2f",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bee5c29613d9f592b8f818d803e2cabe",
     "grade": true,
     "grade_id": "cell-ecc02b55d417c46e",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# BEGIN YOUR CODE HERE\n",
    "\n",
    "\n",
    "# END YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6918a80c",
   "metadata": {},
   "source": [
    "### Exploring importance of scaling\n",
    "rubric={points:10}\n",
    "\n",
    "In this exercise you'll examine whether scaling helps in case of KNNs. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "684b9246",
   "metadata": {},
   "source": [
    "#### Task D6\n",
    "rubric={points:4}\n",
    "\n",
    "Create a column transformer **without** the `StandardScaler` step for `numeric_features`. \n",
    "You can refer your to [Task C1](#Task-C1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15345d81",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "264f82722e13e823794282e4d89b24ab",
     "grade": true,
     "grade_id": "cell-bb06df720e04ebd4",
     "locked": false,
     "points": 4,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# BEGIN YOUR CODE HERE\n",
    "\n",
    "\n",
    "# END YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5132fec6",
   "metadata": {},
   "source": [
    "#### Task D7\n",
    "rubric={points:4}\n",
    "\n",
    "Repeat the steps in [Task D3](#Task-D3) with this new column transformer. Save all results in `results_dic_compare`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0aea091",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bace5328bb1a41629bad752c462cd13d",
     "grade": true,
     "grade_id": "cell-51318be5ac76c162",
     "locked": false,
     "points": 4,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(12345)\n",
    "results_dict_compare = {}  # dictionary to store all the results\n",
    "\n",
    "# BEGIN YOUR CODE HERE\n",
    "\n",
    "\n",
    "# END YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b95a796",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(results_dict_compare).T # compare the result with the outcome without doing feature scaling   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a3f34a4",
   "metadata": {},
   "source": [
    "#### Task D8\n",
    "rubric={points:2}\n",
    "\n",
    "Compare the results of scaled numeric features with unscaled numeric features. \n",
    "1. Is scaling necessary for decision trees? (Yes/No)\n",
    "2. Is scaling necessary for knn? (Yes/No)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4863b3df",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c7eb1956252a1274e0f77af2bbb82939",
     "grade": true,
     "grade_id": "cell-e0a33e852b68eeff",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "<font color='red'>YOUR ANSWER HERE</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "452600db",
   "metadata": {},
   "source": [
    "### Hyperparameter optimization\n",
    "rubric={points:8}\n",
    "\n",
    "In this exercise, you'll carry out hyperparameter optimization for the hyperparameter `n_neighbors` of KNeighborsClassifier. \n",
    "In practice you'll carry out hyperparameter optimization for all different hyperparameters for the most promising classifiers. \n",
    "For the purpose of this assignment, we'll only do it for the K Neighbors classifier with one hyperparameter: `n_neighbors`. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb14229",
   "metadata": {},
   "source": [
    "#### Task D9\n",
    "rubric={points:4}\n",
    "\n",
    "For each `n_neighbors` value in the `param_grid` in the starter code below: \n",
    "- Create a pipeline object with two steps: `preprocessor` from [Task C1](#Task-C1) and KNeighbors classifier with the value of `n_neignbors`.\n",
    "- Carry out 5-fold cross validation with the pipeline using the function `mean_std_cross_val_scores`.  \n",
    "- Store the results in `results_dict_hyper` where the key is the `n_neignbors` value and the value is times and scores.\n",
    "- This step take a few minutes as you are training 4 knn models with 5 fold cross-validation.\n",
    "- Display results as a pandas DataFrame.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e154e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = [2, 3, 4, 5]\n",
    "param_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b463b6ef",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d15cfcef1c387f93deab5191d04fffe3",
     "grade": true,
     "grade_id": "cell-f88c2042ea20cd24",
     "locked": false,
     "points": 4,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "results_dict_hyper = {}\n",
    "\n",
    "# BEGIN YOUR CODE HERE\n",
    "\n",
    "\n",
    "# END YOUR CODE HERE\n",
    "\n",
    "pd.DataFrame(results_dict_hyper).T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe4fa221",
   "metadata": {},
   "source": [
    "You can find the best hyper-parameter from `[2, 3, 4, 5]`. Keep it in your mind."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "916ab427",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Exercise E: Evaluating on the test set\n",
    "<hr>\n",
    "\n",
    "Now that we have a best performing model, it's time to assess our model on the set aside test set. In this exercise you'll examine whether the results you obtained using cross-validation on the train set are consistent with the results on the test set. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e81cd850",
   "metadata": {},
   "source": [
    "### Task E1\n",
    "rubric={points:3}\n",
    "\n",
    "Train the best performing model on **the entire training set** with the pipeline define from [Task D9](#Task-D9).\n",
    "\n",
    "Hint:\n",
    "1. Cross validation is no longer needed as you have the best hyper-parameters\n",
    "2. You build a knn model with `X_train` and `y_train`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe2adff6",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1845c02c0dfe7b292f80758a05d868a5",
     "grade": true,
     "grade_id": "cell-7f2661e2f5b8f4a6",
     "locked": false,
     "points": 3,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# BEGIN YOUR CODE HERE\n",
    "\n",
    "\n",
    "# END YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "413a9750",
   "metadata": {},
   "source": [
    "### Task E2\n",
    "rubric={points:2}\n",
    "\n",
    "Report the prediction of this knn model on `X_test`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df12275",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8b0639f7561e4081379c1764176371c0",
     "grade": true,
     "grade_id": "cell-1dc585847b88c884",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# BEGIN YOUR CODE HERE\n",
    "\n",
    "\n",
    "# END YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8aba0b2",
   "metadata": {},
   "source": [
    "We can evaluate the trained model with `accuracy_score` which means the accurate prediction rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "199a8fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = accuracy_score(y_test, X_test_predictions)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad960eff",
   "metadata": {},
   "source": [
    "### Task E3\n",
    "rubric={points:2}\n",
    "\n",
    "Are the cross-validation results and test results consistent? (Yes or No)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0414b29",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4a79a6c0d515a40917c86448f7671529",
     "grade": true,
     "grade_id": "cell-3a932e8826c11445",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "<font color='red'>YOUR ANSWER HERE</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f98d60",
   "metadata": {},
   "source": [
    "## Submission instructions \n",
    "\n",
    "**PLEASE READ:** When you are ready to submit your assignment do the following:\n",
    "\n",
    "1. Run all cells in your notebook to make sure there are no errors by doing `Kernel -> Restart Kernel and Clear All Outputs` and then `Run -> Run All Cells`. \n",
    "2. Notebooks with cell execution numbers out of order or not starting from “1” will have marks deducted. Notebooks without the output displayed may not be graded at all (because we need to see the output in order to grade your work).\n",
    "3. Upload the assignment at Canvas. \n",
    "4. Finish the corresponding reflection survey."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,md"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "367.2px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
